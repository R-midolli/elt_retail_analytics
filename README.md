ğŸ›’ ELT Retail Analytics (Postgres + dbt + Power BI)

End-to-end **ELT pipeline** built around a classic analytics stack:

- **Python** for extraction + loading (raw â†’ Postgres)
- **dbt** for transformations and a **Star Schema** (staging â†’ marts)
- **Power BI** for the semantic model and dashboard layer

---

## ğŸ§­ Architecture (ELT â†’ dbt â†’ BI)

```mermaid
flowchart TD
  A(Start) --> B(Extract and Load - Python)
  B --> C(Postgres - Docker)
  C --> D(dbt - Staging)
  D --> E(dbt - Marts Star Schema)
  E --> F(Power BI - Semantic Model)
  F --> G(Dashboard)

  subgraph dbt_models[dbt models]
    D
    E
  end
````

---

## ğŸ“Œ Data scope

This dataset is filtered to:

* **France**
* **Europe (Others)**

(confirmed directly from `analytics_staging.stg_sales`).

---

## ğŸ§± Star Schema (Analytics Marts)

**Fact**

* `analytics_marts.fact_sales_star`
  Grain: **invoice line** (invoice_no Ã— stock_code Ã— date Ã— customer)

**Dimensions**

* `analytics_marts.dim_date`
* `analytics_marts.dim_customers`
* `analytics_marts.dim_products`
* `analytics_marts.dim_invoice`

---

## ğŸ•¸ï¸ dbt lineage / graph

The dbt graph screenshot is stored at: `assets/images/dbt_graph.png`

![dbt graph](assets/images/dbt_graph.png)

How it was produced (example):

```bash
cd dbt_retail
uv run dbt docs generate --profiles-dir .
uv run dbt docs serve --profiles-dir .
```

---

## ğŸ“‚ Project structure

```text
ELT_retail_analytics/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # source file(s) (optional in repo)
â”‚   â””â”€â”€ processed/                # filtered / processed exports (optional in repo)
â”œâ”€â”€ dbt_retail/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/              # stg_sales
â”‚   â”‚   â”œâ”€â”€ marts/core/           # dims + facts (star schema)
â”‚   â”‚   â””â”€â”€ reporting/            # KPI models / views
â”‚   â”œâ”€â”€ macros/
â”‚   â””â”€â”€ packages.yml
â”œâ”€â”€ powerbi/
â”‚   â”œâ”€â”€ pbix/
â”‚   â””â”€â”€ screenshots/
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ images/
â”‚       â””â”€â”€ dbt_graph.png
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init.sql
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ elt_step1_extract.py
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## âœ… Prerequisites

* Docker + Docker Compose
* Python (project uses a local virtualenv)
* `uv` installed (or adapt commands to pip)

---

## âš™ï¸ Setup

### 1) Create your `.env`

Copy the example and fill values:

```bash
cp .env.example .env
```

### 2) Start Postgres (Docker)

```bash
docker compose up -d
```

(Optional) verify container:

```bash
docker ps
```

### 3) Create schema / objects (if needed)

```bash
docker exec -it retail_pg psql -U retail_user -d retail -f /sql/init.sql
```

---

## ğŸš€ Run the pipeline

### 1) Extract + Load (Python â†’ Postgres raw)

```bash
source .venv/Scripts/activate   # Windows Git Bash
python elt_step1_extract.py
```

### 2) Build models with dbt (staging â†’ marts)

```bash
cd dbt_retail
set -a && source ../.env && set +a

uv run dbt run --profiles-dir . --select stg_sales dim_products dim_customers dim_date dim_invoice fact_sales fact_sales_star
```

### 3) Run tests

```bash
uv run dbt test --profiles-dir .
```

---

## ğŸ“Š Power BI (semantic model)

In Power BI Desktop:

1. **Get Data â†’ PostgreSQL**
2. Load:

   * `analytics_marts.fact_sales_star`
   * `analytics_marts.dim_date`
   * `analytics_marts.dim_customers`
   * `analytics_marts.dim_products`
   * `analytics_marts.dim_invoice`
3. Create relationships (Many-to-one, Single direction, Active):

   * fact_sales_star[customer_id] â†’ dim_customers[customer_id]
   * fact_sales_star[sales_date] â†’ dim_date[date_day]
   * fact_sales_star[stock_code] â†’ dim_products[stock_code]
   * fact_sales_star[invoice_no] â†’ dim_invoice[invoice_no]

---

## ğŸ” Refresh logic (important)

When dbt rebuilds tables/views:

* In Power BI Desktop: **Home â†’ Refresh**
* If columns changed (new fields): **Transform data â†’ Refresh Preview â†’ Close & Apply**

---

## ğŸ§ª Notes / gotchas

* For star schema relationships, dimension keys must be **unique**.
* If Power BI complains about duplicates, it can be cache/preview.
  The source-of-truth check is in Postgres (dbt tests / SQL checks).

---

## ğŸ“Œ Tech stack

* Postgres (Docker)
* dbt
* Python
* Power BI
